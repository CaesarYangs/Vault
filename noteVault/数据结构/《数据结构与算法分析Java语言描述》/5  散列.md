前一章节的查找树ADT，其允许对元素的集合进行各种操作。

**散列表，即HashTable ADT**。它只支持二叉查找树所允许的一部分操作。

散列表的实现常常叫做散列（hasing）。散列是一种用于以常数平均时间执行插入、删除和查找的技术。但是，那些需要元素间任何排序信息的树操作将不会得到有效的支持。因此类似findMin、findMax以及线性时间将排序过的整个表打印的操作都是散列所不支持的。

Outline
- 实现散列表的几种方法
- 方法比较
- 散列的多种应用
- 将散列表与二叉查找树进行比较

### 一般想法
理想的散列表数据结构只不过是一个包含一些项的具有固定大小的数组。通常查找是对项的某个部分（即数据域）进行的。这部分即关键字（key）。

每个关键字被映射到从0到TableSize-1这个范围中的某个数，并且被放到适当的单元中。这个映射就叫作散列函数(hash function),理想情况下它应该计算起来简单，并且应该保证任何两个不同的关键字映射到不同的单元。不过，这是不可能的，因为单元的数目是有限的，而关键字实际上是用不完的。因此，我们寻找一个散列函数，该函数要在单元之间均匀地分配关键字。

这就是散列的基本想法。剩下的问题就是要选择一个函数，决定当两个关键字散列到同一个值的时候（这叫作冲突(collision))应该做什么以及如何确定散列表的大小。

# 散列函数
通常的经验是不使用所有的字符。此时关键字的长度和性质将影响选择。例如，关键字可能是完整的街道地址，散列函数可以包括街道地址的几个字符，也许还有城市名和邮政编码的几个字符。
有些程序设计人员通过只使用奇数位置上的字符来实现他们的散列函数， 这里有这么一层想法：**用计算散列函数节省下的时间来补偿由此产生的对均匀地分布的函数的轻微干扰。**

剩下的主要编程细节是解决冲突的消除问题。如果当一个元素被插人时与一个已经插入的元素散列到相同的值，那么就产生一个冲突，这个冲突需要消除。解决这种冲突的方法有几种， 我们将讨论其中最简单的两种：分离链接法和开放定址法。

# 分离链接法
**将散列到同一个值的所有元素保留到一个表中。**
为执行一次查找，我们使用散列函数来确定究竟遍历哪个链表。
由散列表存储一个链表数组，它们在构造方法中被指定。

**insert**
检查相应的链表看该元素是否已经处在适当的位置。若此元素是新元素，那么它将被插入到链表的前端，因为新近插入的元素最有可能不久后被访问。

> 除链表外，任何方案都可以解决冲突现象；一棵二叉查找树或甚至另一个散列表都将胜任这个工作，但是，我们期望如果散列表是大的并且散列函数是好的，那么所有的链表都应该是短的，从而任何复杂的尝试就都不值得考虑了。

**装填因子（load factor）**
为散列表中元素的个数对该表大小的比。

***散列表的大小实际上并不重要，而装填因子才是重要的。***
分离链接散列法的一般法则是使得表的大小与预料的元素个数大致相等（换句话说，让入≈1）。在图5-10的程序中， 如果装填因子超过1，那么我们通过调用在26行上的rehash函数扩大散列表的大小。
rehash将在5.5节讨论。正如前面提到的，使表的大小是素数以保证一个好的分布，这个想法很好。

# 不用链表的散列表
分离链接散列算法的缺点是使用一些链表。由于给新单元分配地址需要时间（特别是在其他语言中)，因此这就导致算法的速度有些减慢，同时算法实际上还要求对第二种数据结构的实现。

另有一种不用链表解决冲突的方法是尝试另外一些单元，直到找出空的单元为止。一般来说，对于不适用分离链接的散列表来说，其装填因子应该低于0.5。此类表被称为探测散列表（probing hash table）。

## 线性探测法
函数 *ƒ* 是 *i* 的线性函数。通常情况下为$$f(i) = i$$
**冲突解决方法 *ƒ***
$$ h(x) = (hash(x) + f(i))mod \; TableSize $$
只要表足够大，总能够找到一个自由单元，但同时花费的时间也是相当多的。并且如果表相对较空，这样占据的单元也会开始形成一些区块，其结果称为**一次聚集（primary clustering）**，即散列到区块中的任何关键字都需要多次试选单元才能解决冲突。 ^682d98

**性能分析**
如果入=0.75，那么上面的公式指出在线性探测中一次插入预计8.5次探测。如果λ=0.9， 则预计为50次探测，这就不切实际了。假如聚集不是问题，那么这可与相应的装填因子的4次和10次探测相比。从这些公式看到，如果表可以有多于一半被填满的话，那么线性探测就不是个好办法。然而，如果入=0.5，那么插入操作平均只需要2.5次探测，并且对于成功的查找平均只需要1.5次探测。

## 平方探测法
是消除线性探测中一次[[#^682d98|聚集问题]]的冲突解决方法。是冲突函数为二次的解决方法。
$$ f(i) = i^2 $$

**冲突解决方法 *ƒ***
$$ h(x) = (hash(x) + f(i))mod \; TableSize $$

对于线性探测，让散列表几乎填满元素并不是个好主意，因为此时表的性能会降低。对于平方探测情况甚至更糟：一旦表被填充超过一半，当表的大小不是素数时甚至在表被填充一半之前， 就不能保证一次找到空的单元了。这是因为最多有表的一半可以用作解决冲突的备选位置。

**定理：使用平方探测，如果表有一半是空的，且表大小为素数，总能保证插入一个新的元素。**

即使表被填充的位置仅仅比一半多一个，那么插人都有可能失败（虽然这是非常难于见到的)。因此，把它记住很重要。另外，表的大小是素数也非常重要。如果表的大小不是素数， 则备选单元的个数可能会锐减。例如，若表的大小是16，那么备选单元只能在距散列值1,4或9远处。

虽然平方探测排除了一次聚集，但是散列到同一位置上的那些元素将探测相同的备选单元。这叫作**二次聚集(secondary clustering)**。二次聚集是理论上的一个小缺憾。模拟结果指出对每次查找，它一般要引起另外的少于一半的探测。下面的技术将会排除这个缺憾，不过这要付出计算一个附加的散列函数的代价。

## 双散列
$$ f(i) = i \cdot hash_2(x)$$
将第二个散列应用到x并在距离为hash2（x）等处探测。

双散列函数选取示例：
$$ hash_2(x) = R-(x \ mod \ R) $$
R为小于table大小的素数。

如果表的大小不是素数，那么备选单元就有可能提前用完。然而，如果双散列正确实现，则模拟表明，预期的探测次数几乎和随机冲突解决方法的情形相同。这使得双散列理论上很有吸引力。不过，平方探测不需要使用第二个散列函数，从而在实践中使用可能更简单并且更快，特别对于像串这样的关键字，它们的散列函数计算起来相当耗时。

# 再散列
对于使用平方探测的开放定址散列法，如果散列表填得太满，那么操作的运行时间将开始消耗过长，且插入操作可能失败。这可能发生在有太多的移动和插入混合的场合。
此时，一种解决方法是建立另外一个大约两倍大的表（而且使用一个相关的新散列函数），扫描整个原始散列表，计算每个（未删除的）元素的新散列值并将其插入到新表中。

==如果散列表太满，将会影响到其散列的计算效率，则需要进行扩容。==

整个的操作就叫做**再散列（rehashing）**
显然这是一种开销非常大的操作；其运行时间为O(N),因为有N个元素要再散列而表的大小约为2N,不过，由于不是经常发生，因此实际效果根本没有这么差。特别是在最后的再散列之前必然已经存在N/2次insert，因此添加到每个插入上的花费基本上是一个常数开销。如果这种数据结构是程序的一部分，那么其影响是不明显的。另一方面，如果再散列作为交互系统的一部分运行，那么其插入引起再散列的不幸用户将会感到速度减慢。*新表要做到旧表两倍大小的原因*

1. 只要表满至一半再散列
2. 当插入失败时再散列
3. 途中策略：当散列表到达某一个装填因子时再散列。

由于随着装填因子的增加，散列表的性能确实下降严重。途中策略是最好的策略。

**对于分离链接法来说，再散列过程是相似的。**

**散列过程**
- 先将表扩容
- 再将旧表中元素一一取出，利用新的散列函数装入新的扩容好的表中即完成。

# 标准库中的散列表
通常都是用分离链接法实现的。
## HashSet类



## HashMap类
HashMap的性能常常优于TreeMap的性能，不过不按这两种方式编写代码很难有把握肯定。因此，在HashMap或TreeMap可以接受的情况下，更可取的方法是：使用接口类型Map 进行变量的声明，然后，将TreeMap的实例变成HashMap的实例并进行计时测试。

# 可扩散列
处理数据量太大以至于无法装进主存中的情况。此时主要考虑的是检索数据所需的磁盘次数。

如果使用探测散列或分离链接散列，那么主要的问题在于，在一次查找操作期间冲突可能引起多个区块被检察，甚至对于理想分布的散列表也在所难免。不仅如此，当散列表变得过满的时候，必须执行代价巨大的再散列这一步，它需要O(N)次磁盘访问。

一种聪明的选择叫作**可扩散列(extendible hashing)**,它使得用两次磁盘访问执行一次查找。
插入操作也需要很少的磁盘访问。

