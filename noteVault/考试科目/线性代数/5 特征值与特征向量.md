
> 上次演讲中我闻问道：数学对你来说意味着什么？有些人回答：处理数字，处理结构。那么如果我问音乐对你来说意味着什么，你会回答处理音符吗？
> ——Serge Lang

特征值与特征向量通常被淹没在计算的海洋中被遗忘。

对于一个矩阵来说，代表着对一个坐标轴做相应的线性变换。
但如果此时考虑其中的一个向量，就会发现在变换的过程中，大部分的向量都离开了其张成的空间。

这种情况下，的确有些向量留在了其张成的空间内。这可以被看做是一种巧合。此时，对整个坐标轴的变换对这个特殊向量的作用仅仅是拉伸或压缩而已，如同一个标量。

这个不变的特殊向量所在的轴最终被拉伸，而通常被拉伸为一个特定的数倍——此时线性性质发挥作用，即对整个轴上的所有向量都适用的变换性质。

则对这一变换而言，这些特殊向量的集合就是所有拥有这样性质的向量。而任何其他向量在变换中都会有或多或少的选择，从而离开其张成的空间。

- 特征向量
	- 这些特殊向量就被称为变换的特征向量
- 特征值
	- 每个特征向量所属的值
	- 即衡量特征向量在变换中拉伸或压缩比例的因子

考虑三维空间中的旋转
寻找落在其张成的空间里的向量——即旋转轴本身

- **理解线性变换作用的关键往往较少依赖于选择的特定坐标系**
	- 我们所选的坐标系在其中占了太大比重
	- 更好的方法是求出其特征向量和特征值

**特征向量的概念：**
$$Av = \lambda v$$
这个矩阵作用于此特殊向量上的变化 就等于 其数乘一个数（拉伸或压缩一定比例）

> 矩阵向量乘积 = 特征向量的数乘

求解矩阵A的特征向量和特征值，实际上就是求解使得这个等式成立的向量$v$和数$\lambda$

可以将等式右边重写为矩阵向量的乘积
$$Av = (\lambda E)v$$
$$(A - \lambda E)v = 0$$
当且仅当这个新变换矩阵将空间压缩到更低的维度时，才会产生一个所谓非0向量的解。即非零解。

即：
$$det(A - \lambda E) = 0$$
- 此时，特征值即为由行列式求出的$\lambda$
- 特征向量则使用求出的对应$\lambda$带入矩阵中，求解使得其变换后成为0向量的解，即特征向量

**二维线性变换不一定有特征向量**

**属于单个特征值的特征向量可以不在一条直线上**

---
# 特征基
- Q：如果特征向量恰好是基向量会发生什么？

**对角矩阵**——即所有基向量都是特征向量。矩阵的对角元就是他们的特征值。

对角矩阵在很多方面都容易处理。

如果一个变换有许多基向量，多道有一个能够张成全空间的集合——即n维空间中有n个特征向量线性无关。
那么就能够变换你的坐标系，使得这些特征向量就是基向量。

**即：在另一个坐标系中表示当前坐标系下的变换**
1. 取出想要作为新基的坐标
2. 然后将坐标作为矩阵的列——这个矩阵就是基变换矩阵
3. 在右侧写下基变换矩阵，再在左侧写下基变换矩阵的逆，将原始的变换夹在两个矩阵中间——所得矩阵代表同一个变换，是从新基向量构成的坐标系的角度来看的。

用特征向量完成这个工作的意义在于——这个新矩阵必然是对角矩阵。并且对角元为对应的特征值。因为它所处的基向量在变换中只进行了缩放。

一组基向量构成的集合被称为一组**特征基**

计算矩阵更容易的做法是先变换到特征基，进行相应计算，然后再转换回标准坐标系。

**不是所有矩阵都可以对角化**
比如剪切变换——本质在于特征向量少于所在空间的维数n。不能张成整个空间。

而如果能够变换为一组特征基，矩阵变换会得极为轻松。实现矩阵幂次的计算