# 超越经典搜索问题
> 有些路径不重要，目标状态本身更重要。目标状态本身就是解
 


---
# 局部搜索算法
搜索空间（通常）是连续的；       
通常我们放弃寻找最优解，而是寻找一个好的解
任务通常是寻找某个函数的极大或极小值

状态空间地形图
![一位状态空间地形图 找到局部极值](http://blogstorage.cyang.site/AI_class/c4/climb_hill-1)

如果到目标的路径是无关紧要的，我们可能考虑不同的算法，这类算法不关心路径，局部搜索算法从单个当前结点(而不是多条路径）出发，通常只移动到它的邻近状态。一般情况下不保留搜索路径。

虽然局部搜索算法不是系统化的，但是有两个关键的优点：
（1）它们只用很少的内存通常是常数：
（2）它们经常能在系统化算法不适用的很大或无限的 （连续的）状态空间中找到合理的解。

## 爬山法（局部贪婪算法）
即：通过循环不断寻找当前状态的相邻状态的极值
- 局部爬山法可以找到全局极大值
由于是随记设定的起始位置，不同的起始位置找到的全局极大值都不同
-  e.g. 医院配置问题
- 特例：
	- 局部极大值
	- 山脊
	- 山肩

**变形：**
最陡上升法：选择最大的邻居
随机方法：从高值的邻居中随机选择
随机重启：实施爬山多次
局部束搜索：选择k个最高值的邻居

- Recap
属于数学优化技术
是一个迭代算法
无需维护一个搜索树

## 模拟退火算法
- 利用梯度下降的思路
- 增加温度参数 增加了找到最优解的概率。能更大程度避免陷入局部最优。
根据当前状态不同的温度 以不同的概率来接受下一个邻居

前半部分是更大能量的随机寻找最优解
后半部分是类似于爬山算法的寻找局部最优解

- 在早期，更高的“温度”：更加有可能接受比当前状态还差的邻居
- 越往后，更低的“温度”：更不可能接受比当前状态还差的邻居

## 遗传算法🧬
> 遗传算法( genetic algorithm,或GA)是随机東搜索的一个变形,它通过把两个父状态结合来生成后继,而不是通过修改单一状态进行。这和随机剪枝搜索一样,与自然选择类似,除了我们现在处理的是有性繁殖而不是无性繁殖。

- 种群：从k个随机生成的状态开始
- 适应度函数：每个状态由其目标函数给出适应度评估值
- 杂交点：在字符串中随机选取一个位置
- 变异：每个位置都会按照小的独立概率变异

> 通常的情况是早期的种群是多样化的,因此杂交(类似于模拟退火)在搜索过程的早期阶段在状态空间中采用较大的步调,而在后来当大多数个体都很相似的时候采用较小的步调

像随机東束搜索一样,遗传算法结合了上山趋势、随机探索和在并行搜索线程之间交换信息。遗传算法最主要的优点,如果算是,来自于杂交操作。然而可以在数学上证明,如果基因编码的位置在初始的时候就允许随机转换,杂交就没有优势了。直观上说,杂交的优势在于它能够将独立发展出来的能执行有用功能的字符区域结合起来,因此提高了搜索的粒度。

**一般框架：**
- 编码
对种群中的个体（状态）进行编码表示，一般可用有限长度的字符串表示（可以是0、1串或数字）
- 适应度函数
每个状态（个体）都由它的适应度函数给出评估值
对好的状态，适应度函数应给出较高的评估值
- 个体选择策略
轮盘赌法：适应度更高的被选中的概率就更高
锦标赛法
- 遗传操作
交叉率
变异率

### 遗传算法特点：
1. 遗传算法是一个随机搜索算法，适用于数值求解具有多参数、多变量、多目标等复杂的最优化问题。
2. 遗传算法对待求解问题的指标函数没有什么特殊的要求，比如不要求诸如连续性、导数存在、单峰值假设等。甚至于不需要显式的写出指标函数。
3. 在经过编码以后，遗传算法几乎不需要任何与问题有关的知识，唯一需要的信息是适应值的计算。也不需要使用者对问题有很深入的了解和求解技巧，通过选择、交叉和变异等简单的操作求解复杂的问题，是一个比较通用的优化算法。
4. 遗传算法具有天然的并行性，适用于并行求解。

**收敛性定理**
如果在代的进化过程中，遗传算法每次保留到目前为止的最好解，并且算法以交叉和变异为其随机化操作，则对于一个全局最优化问题，当进化代数趋于无穷时，遗传算法找到最优解的概率为1。 

# 连续空间内局部搜索
- 属于连续函数的优化问题
## 梯度上升/下降
- 给定一个曲面 z=f(x,y)，以及一个点(x,y)，一个梯度是一个向量
- 该向量朝向在该点处函数值上升最快（最陡）的方向
- 该向量的反方向是函数值下降最快方向
- 主要流程：
1. 梯度方法计算函数的梯度▽f，并用它来增加/减少函数值
2. 如果▽f(x)=0，我们就达到了一个局部极大/极小值
- 到达的极小值之处和起始点的选取有关
- 确定学习率





